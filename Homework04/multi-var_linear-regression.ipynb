{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 04\n",
    "## Multiple variable linear regression by 20175437 신준섭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input points\n",
    "* ### Load train datas from `data_train.csv`\n",
    "$$\\{ (x^{(i)}, y^{(i)}, z^{(i)}, h^{(i)} ) \\}$$\n",
    "\n",
    "* ### Load test datas from `data_test.csv`\n",
    "$$\\{ (x^{(i)}, y^{(i)}, z^{(i)}, h^{(i)} ) \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def read_datafiles(filename):\n",
    "    datas, target = [], []\n",
    "    with open(filename, newline='') as the_file:\n",
    "        reader  = csv.reader(the_file, delimiter=',')\n",
    "        for i in reader:\n",
    "            datas.append([float(1.0), float(i[0]), float(i[1]), float(i[2])])\n",
    "            target.append([float(i[3])])\n",
    "    return np.matrix(datas), np.matrix(target)\n",
    "\n",
    "train_data, train_target = read_datafiles(\"data_train.csv\")\n",
    "test_data, test_target = read_datafiles(\"data_test.csv\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Model\n",
    "### * Linear model of 3 inputs\n",
    "$$f_\\theta(x, y, z) = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z$$\n",
    "$$where \\theta_0, \\theta_1, \\theta_2, \\theta_3 \\in \\mathbb{R} $$\n",
    "\n",
    "### * Vector equation form\n",
    "$$ \\Theta = [\\theta_0, \\theta_1, \\theta_2, \\theta_3 ]^T $$\n",
    "$$ \\mathbf{x} = [1, x, y, z]^T $$\n",
    "$$ f(\\Theta, \\mathbf{x}) =   \\mathbf{x}^T \\cdot \\Theta $$\n",
    "\n",
    "### * Matrix form\n",
    "\\begin{equation*}\n",
    "    X = \\begin{bmatrix}\n",
    "        \\mathbf{x}_1^T \\\\\n",
    "        \\cdot \\cdot \\cdot \\\\\n",
    "        \\mathbf{x}_m^T\n",
    "    \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "$$ F = X \\cdot \\Theta$$\n",
    "\n",
    "where for $m$ data points,\n",
    "$$F \\in \\mathbb{R}^{m \\times 1},  X \\in \\mathbb{R}^{m \\times 4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Objective function\n",
    "\n",
    "### * The target value for $\\mathbf{x}_i$ is $h_i$ so\n",
    "$$H = [h_1, \\cdot \\cdot \\cdot, h_N]^T$$\n",
    "\n",
    "### * Scalar representation\n",
    "$$J(\\theta_0, \\theta_1, \\theta_2, \\theta_3) = \\frac{1}{2 m} \\sum_{i=1}^m ( \\theta_0 + \\theta_1 x^{(i)} + \\theta_2 y^{(i)} + \\theta_3 z^{(i)} - h^{(i)} )^2$$\n",
    "\n",
    "### * Matrix representation\n",
    "$$J(\\Theta, \\mathbf{x}) = \\frac{1}{2m} \\sum_{i=1}^{m} [(F - H)^2]_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoss(X, T, H):\n",
    "    m = H.shape[0]\n",
    "    return (1.0 / (2.0 * m)) * np.sum(np.square(np.matmul(X, T) - H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient Descent\n",
    "- $\\theta_0^{(t+1)} := \\theta_0^{(t)} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_\\theta(x^{(i)}, y^{(i)}, z^{(i)}) - h^{(i)})$\n",
    "- $\\theta_1^{(t+1)} := \\theta_1^{(t)} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_\\theta(x^{(i)}, y^{(i)}, z^{(i)}) - h^{(i)}) x^{(i)}$\n",
    "- $\\theta_2^{(t+1)} := \\theta_2^{(t)} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_\\theta(x^{(i)}, y^{(i)}, z^{(i)}) - h^{(i)}) y^{(i)}$\n",
    "- $\\theta_3^{(t+1)} := \\theta_3^{(t)} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (f_\\theta(x^{(i)}, y^{(i)}, z^{(i)}) - h^{(i)}) z^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradient(X, T, H):\n",
    "    m = H.shape[0]\n",
    "    gradients = np.matrix([[0.0], [0.0], [0.0], [0.0]])\n",
    "    diff = np.matmul(X, T) - H\n",
    "\n",
    "    idx = 0\n",
    "    while idx < X.shape[1]:\n",
    "        gradients[idx] = (1.0/m) * np.sum(np.multiply(diff, X[:,idx]))\n",
    "        idx = idx + 1\n",
    "\n",
    "    return gradients\n",
    "\n",
    "def gradientDescent(X, T, H, lr = 0.00001):\n",
    "    grads = getGradient(X, T, H)\n",
    "    return T - lr * grads\n",
    "\n",
    "def testConvergence(X, T, H, threshold = 10.0):\n",
    "    grads = getGradient(X, T, H)\n",
    "    return np.sqrt(np.sum(np.square(grads))) < threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "thetas = np.matrix([[0.0], [0.0], [0.0], [0.0]])\n",
    "\n",
    "while testConvergence(train_data, thetas, train_target) == False:\n",
    "    thetas = gradientDescent(train_data, thetas, train_target)"
   ]
  }
 ]
}